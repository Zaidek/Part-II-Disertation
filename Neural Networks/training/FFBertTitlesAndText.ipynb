{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import regex\n",
    "import string\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ML libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset and models used\n",
    "sys.path.insert(0, '//wsl$/Ubuntu/home/zaidek/Part-II-Disertation/Neural Networks')\n",
    "from ipynb.fs.defs.datasets import BertProcessedTitleEmbeddingTitleAndTextDataset\n",
    "from ipynb.fs.defs.models import FFNetworkBertEmbedding\n",
    "from ipynb.fs.defs.FFtraining import train_model_bert\n",
    "from ipynb.fs.defs.FFtraining import define_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "with open(\"../data/data_train\", \"rb\") as fb:\n",
    "    training_data = pickle.load(fb)\n",
    "\n",
    "# import validation data\n",
    "with open(\"../data/data_valid\", \"rb\") as fb:\n",
    "    validation_data = pickle.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try set gpu as training device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex data\n",
    "train_data_indexed = training_data.reset_index(drop=True)\n",
    "valid_data_indexed = validation_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cols which are used in model\n",
    "req_cols_without_url = [\"title\", \"text\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract specific cols needed\n",
    "scores = train_data_indexed.score\n",
    "training_data_indexed = train_data_indexed[req_cols_without_url]\n",
    "\n",
    "validation_scores = valid_data_indexed.score\n",
    "validation_data_indexed = valid_data_indexed[req_cols_without_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan values in normal data\n",
    "training_data_indexed.title = training_data_indexed.title.fillna(\"\")\n",
    "training_data_indexed.text = training_data_indexed.fillna(\"\")\n",
    "\n",
    "validation_data_indexed.title = validation_data_indexed.title.fillna(\"\")\n",
    "validation_data_indexed.text = validation_data_indexed.text.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loader parameters\n",
    "cutoff = 20\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "train_sampler = define_sampler(scores, cutoff)\n",
    "valid_sampler = define_sampler(validation_scores, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bert embedding datasets\n",
    "dataset_train = BertProcessedTitleEmbeddingTitleAndTextDataset(training_data_indexed, scores, cutoff)\n",
    "dataset_valid = BertProcessedTitleEmbeddingTitleAndTextDataset(validation_data_indexed, validation_scores, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batched bert embedding loaders\n",
    "use_sampler = False\n",
    "train_loader, valid_loader = None, None\n",
    "if use_sampler:\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=dataset_valid, batch_size=batch_size, sampler=valid_sampler)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=dataset_valid, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dimensions of bert model\n",
    "embedding_dim = 768 * 2\n",
    "output_dim = 1\n",
    "\n",
    "# instantiate bert model\n",
    "model = FFNetworkBertEmbedding(output_dim, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# define paramters for optimizers\n",
    "learning_rate = 0.01\n",
    "\n",
    "# define basic optimizer class\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model_final, train_losses, valid_losses = train_model_bert(model, train_loader, valid_loader, loss_func, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8cd98ac651c668ce2c6203d75b23f2d5bc0a45f06efaf825f1ea3a340dc3a78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
